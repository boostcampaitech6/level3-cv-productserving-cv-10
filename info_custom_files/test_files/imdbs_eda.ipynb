{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .npy 파일 로드 및 데이터 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 동일한 파일에 JSON 데이터를 다시 저장합니다.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 18\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(data, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/encoder.py:314\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m buf \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# Subclasses of int/float may override __repr__, but we still\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# want to encode them as integers/floats in JSON. One example\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# within the standard library is IntEnum.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m buf \u001b[38;5;241m+\u001b[39m _intstr(value)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# see comment above for int\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m buf \u001b[38;5;241m+\u001b[39m _floatstr(value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "ocr_dir = '../data/sp-vqa/ocr'\n",
    "\n",
    "# ocr_dir 디렉토리 안의 모든 .json 파일을 찾습니다.\n",
    "json_files = glob.glob(os.path.join(ocr_dir, '*.json'))\n",
    "\n",
    "# 모든 JSON 파일에 대해 반복합니다.\n",
    "for json_file in json_files:\n",
    "    # 파일을 열어 JSON 데이터를 로드합니다.\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 동일한 파일에 JSON 데이터를 다시 저장합니다.\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/sp-vqa/ocr/ffbf0023_4.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecognitionResults\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "with open('../data/sp-vqa/ocr/ffbf0023_4.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "print(data)\n",
    "print(data['recognitionResults'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'numpy.ndarray'>\n",
      "Data shape: (3288,)\n",
      "Data size: 3288\n",
      "First element type: <class 'dict'>\n",
      "Keys in the first dictionary element: dict_keys(['question', 'image_id', 'image_classes', 'extra_info', 'image_width', 'image_height', 'question_tokens', 'question_id', 'set_name', 'image_name', 'image_path', 'feature_path', 'ocr_tokens', 'ocr_info', 'ocr_normalized_boxes', 'obj_normalized_boxes'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# .npy 파일 로드\n",
    "# data = np.load('/home/ges/level3-cv-productserving-cv-10/data/infographics/imdb/new_imdb_train.npy', allow_pickle=True)\n",
    "data = np.load('/home/ges/level3-cv-productserving-cv-10/data/infographics/imdb/new_imdb_test.npy', allow_pickle=True)\n",
    "\n",
    "# 데이터 타입 출력\n",
    "print(f\"Data type: {type(data)}\")\n",
    "\n",
    "# 데이터의 전체 구조 확인 (예: shape, size)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Data size: {data.size}\")\n",
    "\n",
    "# 데이터의 첫 번째 요소 타입 확인\n",
    "print(f\"First element type: {type(data[0])}\")\n",
    "\n",
    "# 데이터의 첫 번째 요소 내용 확인 (예시로, 배열이나 리스트일 경우)\n",
    "if isinstance(data[0], (np.ndarray, list)):\n",
    "    print(f\"First element content: {data[0]}\")\n",
    "\n",
    "# 더 구체적인 데이터 구조 및 라벨링 확인\n",
    "# 예: 첫 번째 요소가 딕셔너리라면, 키를 확인하여 어떤 라벨/필드가 있는지 확인\n",
    "if isinstance(data[1], dict):\n",
    "    print(\"Keys in the first dictionary element:\", data[0].keys())\n",
    "    \n",
    "    \n",
    "\n",
    "# for item in data :\n",
    "#     print(item.keys())\n",
    "# if isinstance(data[0], dict):\n",
    "#     print(\"Keys in the first dictionary element:\", data[0].values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'V', 'E', 'R', 'y', 'B', 'O', 'D', 'P', 'L', 'A', 'y', 'S', '10+', 'things', 'you', \"didn't\", 'know', 'about', 'online', 'contests', '&', 'promotions', 'PLAYERS', 'PROFILE', '53%', 'male', '68%', '47%', '18 years old', 'femate', 'OUT', 'OF', '10', 'The', 'average', 'age', 'is', '30', 'people', 'have', 'ever', 'played', 'a', 'game', 'OVER', '70%', 'OF', 'BIG', 'COMPANIES', 'will', 'use', 'gamification', 'in', 'their', 'strategies', 'by', '2014', 'companies', 'Running', 'CONTESTS', 'TOP', '3', 'APPS', 'industries', 'most', 'popular', 'Sweepstakes', 'IJ', 'Quiz', '1', 'Instant', '2', 'Photo', 'Contest', '3', 'Survey', 'Others', 'Tip:', 'match', 'your', 'goals', 'with', 'the', 'right', 'application', 'For', 'instance,', 'developping', 'your', 'fanbase', 'will', 'be', 'easier', 'using', 'an', 'Instant', 'Win', 'app.', 'while a', 'Photo', 'Photo Contest wi', 'Contest:', 'will', 'be', 'better', 'engage', 'with', 'your', 'audience.', 'Besides', 'Scavenger', 'Hunt', 'is a', 'very', 'good', 'choice', 'to', 'drive', 'sales', 'in your', 'shops.', 'Best', 'duration', 'for', 'a', 'contest', 'Best', 'time', 'of', 'the', 'year', 'to', 'launch', 'contests', 'Jan.', 'Feb.', 'march', 'Apr', 'may', 'June', 'July', 'Aug', 'Sept', 'now', 'Dec', '20 25', 'best', 'campaign', 'o days', 'most', 'European', 'brands', 'launch', 'their', 'campaigns', 'June', 'and', 'november', '10X', 'NEWS', '1/3', 'Amount', 'of', 'entrants', 'Entrants', 'accepting', 'gathered', 'by', 'to receive', 'informo', 'campaigns', 'from', 'brand', 'and', 'advertising', 'budget', 'partners', '2:30', 'Tip:', 'Using', 'several', 'channels', 'boosts', 'your', 'Average', 'time', 'spent', 'promotions', 'on', 'contest', 'app', 'performance!', '+34%', '17500', '8x', 'PRIZES', 'Most', 'popular', 'categories', 'Travels', '20%', '369', 'Entertainment', 'Average', 'music', 'N', 'Technology', 'B', '13%', 'Fashion', 'Information', 'asked', 'by', 'brands', 'in', 'the', 'participation', 'form', 'Email', '100%', 'Tip:', '93%', 'Just ask', 'First', 'name', 'information', 'you', 'Last', 'name', '92%', 'really', 'need', 'many', 'fields', 'Age', '64%', 'could', 'the', 'entrants.', 'Country', '52%', 'Postal', 'address', '30%', 'Launch', 'awesome', 'promotion', 'and', 'contest', 'apps!', 'Powerfr', 'Apps', 'Triangle', 'of', 'success', '83', 'Incentive', 'prizes', 'Targeted', 'advertising', 'Sources:', 'Kontest', 'internal', 'data', 'theesa', 'com', 'gartner', 'com', 'kontest', 'Build', 'awesome', 'contest', 'and', 'promotion', 'apps', 'for', 'Facebook,', 'web', 'and', 'mobile', 'kontestapp.']\n",
      "37143.jpeg\n"
     ]
    }
   ],
   "source": [
    "print(data[1]['ocr_tokens'])\n",
    "print(data[1]['image_name'])\n",
    "# print(data[0])\n",
    "# print(len(data[1]['ocr_tokens']))\n",
    "# print(data[1]['ocr_tokens'])\n",
    "# print(data[1]['question'])\n",
    "# print(data[1]['question_id'])\n",
    "# print(data[1]['question_tokens']) # 이거 안드러가있음\n",
    "# print(len(data[1]['ocr_normalized_boxes']))\n",
    "# print(data[2231]['valid_answers'])\n",
    "# print(data[2231]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Succeeded',\n",
       " 'recognitionResults': [{'page': 1,\n",
       "   'clockwiseOrientation': 359.79,\n",
       "   'width': 1695,\n",
       "   'height': 2025,\n",
       "   'unit': 'pixel',\n",
       "   'lines': [{'boundingBox': [576, 30, 992, 26, 993, 126, 577, 130],\n",
       "     'text': 'Confidential',\n",
       "     'words': [{'boundingBox': [586, 30, 993, 36, 994, 119, 584, 131],\n",
       "       'text': 'Confidential',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [1081, 34, 1124, 31, 1125, 53, 1082, 56],\n",
       "     'text': '.. ..',\n",
       "     'words': [{'boundingBox': [1080, 34, 1097, 32, 1099, 54, 1081, 55],\n",
       "       'text': '..',\n",
       "       'confidence': 'Low'},\n",
       "      {'boundingBox': [1102, 32, 1122, 31, 1124, 53, 1103, 54],\n",
       "       'text': '..'}]},\n",
       "    {'boundingBox': [695, 202, 994, 204, 994, 236, 694, 234],\n",
       "     'text': 'RJRT PR APPROVAL',\n",
       "     'words': [{'boundingBox': [699, 203, 779, 204, 779, 234, 699, 234],\n",
       "       'text': 'RJRT',\n",
       "       'confidence': 'Low'},\n",
       "      {'boundingBox': [793, 204, 832, 204, 832, 234, 793, 234], 'text': 'PR'},\n",
       "      {'boundingBox': [848, 204, 995, 204, 995, 237, 848, 234],\n",
       "       'text': 'APPROVAL'}]},\n",
       "    {'boundingBox': [254, 295, 343, 294, 344, 322, 255, 323],\n",
       "     'text': 'DATE :',\n",
       "     'words': [{'boundingBox': [259, 296, 330, 295, 331, 322, 259, 323],\n",
       "       'text': 'DATE'},\n",
       "      {'boundingBox': [335, 295, 343, 295, 344, 322, 337, 322], 'text': ':'}]},\n",
       "    {'boundingBox': [396, 262, 561, 262, 559, 333, 398, 327],\n",
       "     'text': '1/8/13',\n",
       "     'words': [{'boundingBox': [400, 258, 556, 261, 555, 332, 399, 329],\n",
       "       'text': '1/8/13',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [399, 331, 644, 330, 645, 410, 400, 412],\n",
       "     'text': 'Ru alAs',\n",
       "     'words': [{'boundingBox': [426, 334, 523, 331, 522, 410, 426, 412],\n",
       "       'text': 'Ru'},\n",
       "      {'boundingBox': [548, 331, 644, 333, 643, 413, 547, 411],\n",
       "       'text': 'alAs',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [249, 410, 658, 409, 659, 448, 250, 448],\n",
       "     'text': 'PROPOSED RELEASE DATE:',\n",
       "     'words': [{'boundingBox': [259, 416, 403, 414, 405, 445, 260, 444],\n",
       "       'text': 'PROPOSED'},\n",
       "      {'boundingBox': [422, 413, 551, 412, 553, 447, 423, 445],\n",
       "       'text': 'RELEASE'},\n",
       "      {'boundingBox': [570, 411, 657, 410, 659, 449, 572, 447],\n",
       "       'text': 'DATE:',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [673, 400, 970, 385, 973, 449, 677, 464],\n",
       "     'text': 'for response',\n",
       "     'words': [{'boundingBox': [688, 400, 764, 398, 766, 457, 690, 464],\n",
       "       'text': 'for',\n",
       "       'confidence': 'Low'},\n",
       "      {'boundingBox': [777, 398, 972, 393, 972, 445, 778, 456],\n",
       "       'text': 'response',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [257, 472, 530, 471, 531, 504, 258, 505],\n",
       "     'text': 'FOR RELEASE TO:',\n",
       "     'words': [{'boundingBox': [260, 474, 314, 473, 315, 505, 260, 505],\n",
       "       'text': 'FOR'},\n",
       "      {'boundingBox': [330, 473, 462, 472, 462, 506, 331, 505],\n",
       "       'text': 'RELEASE',\n",
       "       'confidence': 'Low'},\n",
       "      {'boundingBox': [480, 472, 531, 473, 530, 505, 480, 505],\n",
       "       'text': 'TO:',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [252, 529, 411, 530, 410, 565, 251, 564],\n",
       "     'text': 'CONTACT:',\n",
       "     'words': [{'boundingBox': [258, 531, 409, 530, 412, 565, 259, 564],\n",
       "       'text': 'CONTACT:'}]},\n",
       "    {'boundingBox': [429, 521, 663, 511, 666, 568, 432, 578],\n",
       "     'text': 'P. CARTER',\n",
       "     'words': [{'boundingBox': [445, 521, 490, 519, 492, 577, 447, 578],\n",
       "       'text': 'P.'},\n",
       "      {'boundingBox': [501, 519, 658, 513, 660, 568, 503, 577],\n",
       "       'text': 'CARTER'}]},\n",
       "    {'boundingBox': [256, 653, 410, 654, 410, 682, 255, 681],\n",
       "     'text': 'ROUTE TO',\n",
       "     'words': [{'boundingBox': [258, 656, 347, 656, 349, 683, 259, 681],\n",
       "       'text': 'ROUTE'},\n",
       "      {'boundingBox': [368, 655, 401, 654, 403, 682, 369, 683],\n",
       "       'text': 'TO',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [1037, 711, 1194, 715, 1193, 748, 1036, 744],\n",
       "     'text': 'Initials',\n",
       "     'words': [{'boundingBox': [1048, 713, 1194, 715, 1193, 749, 1047, 745],\n",
       "       'text': 'Initials',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [1357, 713, 1436, 718, 1434, 751, 1356, 745],\n",
       "     'text': 'pate',\n",
       "     'words': [{'boundingBox': [1359, 712, 1433, 717, 1431, 750, 1356, 745],\n",
       "       'text': 'pate',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [253, 773, 481, 775, 480, 807, 252, 806],\n",
       "     'text': 'Peggy Carter',\n",
       "     'words': [{'boundingBox': [257, 774, 348, 777, 348, 807, 257, 804],\n",
       "       'text': 'Peggy',\n",
       "       'confidence': 'Low'},\n",
       "      {'boundingBox': [366, 778, 478, 776, 478, 804, 366, 807],\n",
       "       'text': 'Carter'}]},\n",
       "    {'boundingBox': [1019, 756, 1129, 755, 1129, 804, 1017, 808],\n",
       "     'text': 'Ac',\n",
       "     'words': [{'boundingBox': [1053, 755, 1127, 753, 1129, 804, 1054, 806],\n",
       "       'text': 'Ac',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [250, 833, 458, 837, 457, 866, 249, 862],\n",
       "     'text': 'Maura Payne',\n",
       "     'words': [{'boundingBox': [254, 835, 349, 838, 349, 864, 254, 863],\n",
       "       'text': 'Maura'},\n",
       "      {'boundingBox': [367, 838, 456, 837, 457, 866, 367, 865],\n",
       "       'text': 'Payne',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [254, 890, 473, 892, 472, 925, 253, 924],\n",
       "     'text': 'David Fishel',\n",
       "     'words': [{'boundingBox': [254, 893, 349, 894, 351, 925, 256, 923],\n",
       "       'text': 'David'},\n",
       "      {'boundingBox': [365, 894, 472, 892, 473, 925, 367, 925],\n",
       "       'text': 'Fishel',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [225, 943, 566, 931, 568, 979, 227, 991],\n",
       "     'text': 'Tom GRISCom',\n",
       "     'words': [{'boundingBox': [243, 944, 319, 940, 320, 989, 244, 989],\n",
       "       'text': 'Tom'},\n",
       "      {'boundingBox': [355, 939, 562, 935, 563, 977, 355, 988],\n",
       "       'text': 'GRISCom',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [236, 1003, 543, 983, 546, 1030, 239, 1050],\n",
       "     'text': 'Diane Barrows',\n",
       "     'words': [{'boundingBox': [247, 1003, 370, 994, 371, 1043, 248, 1049],\n",
       "       'text': 'Diane'},\n",
       "      {'boundingBox': [391, 993, 544, 985, 546, 1030, 392, 1042],\n",
       "       'text': 'Barrows',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [244, 1053, 514, 1034, 518, 1087, 248, 1105],\n",
       "     'text': 'Ed Blackmer',\n",
       "     'words': [{'boundingBox': [249, 1056, 310, 1050, 313, 1101, 252, 1106],\n",
       "       'text': 'Ed'},\n",
       "      {'boundingBox': [336, 1047, 511, 1038, 516, 1088, 340, 1099],\n",
       "       'text': 'Blackmer'}]},\n",
       "    {'boundingBox': [241, 1115, 500, 1088, 506, 1140, 247, 1167],\n",
       "     'text': 'Tow Rucker',\n",
       "     'words': [{'boundingBox': [256, 1115, 330, 1107, 334, 1159, 260, 1165],\n",
       "       'text': 'Tow'},\n",
       "      {'boundingBox': [371, 1103, 500, 1089, 504, 1141, 376, 1155],\n",
       "       'text': 'Rucker',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [1029, 1119, 1124, 1112, 1128, 1172, 1038, 1185],\n",
       "     'text': 'TR',\n",
       "     'words': [{'boundingBox': [1037,\n",
       "        1118,\n",
       "        1120,\n",
       "        1109,\n",
       "        1127,\n",
       "        1174,\n",
       "        1044,\n",
       "        1183],\n",
       "       'text': 'TR',\n",
       "       'confidence': 'Low'}]},\n",
       "    {'boundingBox': [393, 1252, 1283, 1253, 1282, 1289, 392, 1288],\n",
       "     'text': 'Return to Peggy Carter, PR, 16 Reynolds Building',\n",
       "     'words': [{'boundingBox': [399, 1254, 512, 1254, 511, 1288, 398, 1287],\n",
       "       'text': 'Return'},\n",
       "      {'boundingBox': [529, 1254, 568, 1254, 568, 1288, 528, 1288],\n",
       "       'text': 'to'},\n",
       "      {'boundingBox': [584, 1254, 679, 1254, 679, 1289, 583, 1288],\n",
       "       'text': 'Peggy'},\n",
       "      {'boundingBox': [693, 1254, 830, 1254, 830, 1289, 692, 1289],\n",
       "       'text': 'Carter,'},\n",
       "      {'boundingBox': [841, 1254, 902, 1254, 902, 1289, 840, 1289],\n",
       "       'text': 'PR,'},\n",
       "      {'boundingBox': [917, 1254, 956, 1254, 956, 1290, 917, 1290],\n",
       "       'text': '16'},\n",
       "      {'boundingBox': [969, 1254, 1121, 1254, 1122, 1290, 969, 1290],\n",
       "       'text': 'Reynolds'},\n",
       "      {'boundingBox': [1135, 1254, 1280, 1253, 1281, 1289, 1135, 1290],\n",
       "       'text': 'Building'}]},\n",
       "    {'boundingBox': [1527, 1536, 1500, 1721, 1468, 1716, 1495, 1532],\n",
       "     'text': '51142 3977',\n",
       "     'words': [{'boundingBox': [1527,\n",
       "        1542,\n",
       "        1514,\n",
       "        1630,\n",
       "        1483,\n",
       "        1623,\n",
       "        1495,\n",
       "        1536],\n",
       "       'text': '51142'},\n",
       "      {'boundingBox': [1511, 1648, 1499, 1719, 1470, 1712, 1481, 1641],\n",
       "       'text': '3977'}]},\n",
       "    {'boundingBox': [1496, 1917, 1529, 1922, 1527, 1940, 1495, 1934],\n",
       "     'text': '. .',\n",
       "     'words': [{'boundingBox': [1499,\n",
       "        1916,\n",
       "        1504,\n",
       "        1917,\n",
       "        1501,\n",
       "        1935,\n",
       "        1496,\n",
       "        1934],\n",
       "       'text': '.'},\n",
       "      {'boundingBox': [1507, 1918, 1519, 1920, 1516, 1938, 1504, 1935],\n",
       "       'text': '.'}]},\n",
       "    {'boundingBox': [373, 1983, 1315, 1982, 1316, 2017, 374, 2018],\n",
       "     'text': 'Source: https://www.industrydocuments.ucsf.edu/docs/xnb10037',\n",
       "     'words': [{'boundingBox': [378, 1985, 492, 1986, 493, 2018, 379, 2017],\n",
       "       'text': 'Source:'},\n",
       "      {'boundingBox': [498, 1986, 1314, 1983, 1315, 2018, 499, 2018],\n",
       "       'text': 'https://www.industrydocuments.ucsf.edu/docs/xnb10037',\n",
       "       'confidence': 'Low'}]}]}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('../data/sp-vqa/ocr/xnbl0037_1.json','r') as f:\n",
    "    a = json.load(f)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'confidential'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]['ocr_tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34454277, 0.01481481, 0.58643067, 0.06469136], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]['ocr_normalized_boxes'][0]\n",
    "# len(data)\n",
    "# data[1]\n",
    "\n",
    "# import json\n",
    "\n",
    "\n",
    "# with open('asdsadasd.json', 'w', encoding='utf-8') as ff:\n",
    "#     json.dump(data[1], ff, indent=4)\n",
    "# data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3445427728613569, 0.014814814814814815, 0.5864306784660767, 0.06469135802469136]\n"
     ]
    }
   ],
   "source": [
    "original_bbox = [586, 30, 993, 36, 994, 119, 584, 131]\n",
    "\n",
    "# 이미지의 너비와 높이\n",
    "image_width = 1695\n",
    "image_height = 2025\n",
    "\n",
    "# 최소/최대 좌표 계산\n",
    "min_x = min(original_bbox[::2])  # x 좌표는 짝수 인덱스\n",
    "max_x = max(original_bbox[::2])\n",
    "min_y = min(original_bbox[1::2])  # y 좌표는 홀수 인덱스\n",
    "max_y = max(original_bbox[1::2])\n",
    "\n",
    "# 정규화\n",
    "normalized_bbox = [\n",
    "    min_x / image_width, min_y / image_height,\n",
    "    max_x / image_width, max_y / image_height\n",
    "]\n",
    "\n",
    "print(normalized_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_time: <class 'float'>\n",
      "version: <class 'float'>\n",
      "dataset_type: <class 'str'>\n",
      "has_answer: <class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "# 예: 중첩된 구조 탐색\n",
    "if isinstance(data[0], dict):\n",
    "    for key, value in data[0].items():\n",
    "        print(f\"{key}: {type(value)}\")\n",
    "\n",
    "        # 딕셔너리 또는 리스트 내부의 더 세부적인 정보 확인\n",
    "        if isinstance(value, (dict, list)):\n",
    "            print(f\"Sample from '{key}': {value[:1]}\")  # 첫 번째 요소 출력\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
