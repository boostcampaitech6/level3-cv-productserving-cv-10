{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_path = './hy_info/Task3_test/'\n",
    "default_path = './hy_info/task3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(default_path+'/qas/infographicsVQA_train_v1.0.json', 'r') as file:\n",
    "    data_train = json.load(file)\n",
    "\n",
    "with open(default_path+'/qas/infographicsVQA_val_v1.0_withQT.json', 'r') as file:\n",
    "    data_valid = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train\n",
    "# data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/ges/level3-cv-productserving-cv-10/data/infographics/qas/infographicsVQA_val_v1.0_withQT.json', 'r') as file:\n",
    "#     data = json.load(file)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_npy(data,file_name):    \n",
    "    imdb_data = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for item in data['data']:\n",
    "        \n",
    "        image_path = default_path+f\"/images/{item['image_local_name']}\"  # 이미지 폴더 경로 수정\n",
    "        \n",
    "        # 이미지 크기 정보를 읽음\n",
    "        with Image.open(image_path) as img:\n",
    "            image_width, image_height = img.size\n",
    "        \n",
    "        \n",
    "        # OCR 출력 파일 로드\n",
    "        with open(default_path+f\"/ocrs/{item['ocr_output_file']}\", 'r') as ocr_file:\n",
    "            ocr_data = json.load(ocr_file)\n",
    "        ocr_tokens = []\n",
    "        ocr_normalized_boxes = []\n",
    "        \n",
    "        # print(ocr_data.keys())\n",
    "        if 'WORD' in ocr_data :\n",
    "            for word_info in ocr_data['WORD']:\n",
    "            # OCR 토큰 추가\n",
    "                ocr_tokens.append(word_info['Text'])\n",
    "\n",
    "            # BoundingBox 정보를 사용하여 정규화된 박스 생성\n",
    "            # 'Left', 'Top'은 박스의 좌상단 좌표, 'Width', 'Height'는 박스의 너비와 높이입니다.\n",
    "                bounding_box = word_info['Geometry']['BoundingBox']\n",
    "                \n",
    "                normalized_box = [\n",
    "                    bounding_box['Left'],\n",
    "                    bounding_box['Top'],\n",
    "                    bounding_box['Left'] + bounding_box['Width'],\n",
    "                    bounding_box['Top'] + bounding_box['Height']\n",
    "                ]\n",
    "                ocr_normalized_boxes.append(normalized_box)\n",
    "        else :\n",
    "            print(item)\n",
    "            print(False)\n",
    "            break\n",
    "        \n",
    "        # print(ocr_tokens)\n",
    "        # print(ocr_normalized_boxes)\n",
    "        # 이미지 사이즈, OCR 정보 등을 필요에 따라 처리\n",
    "        # 예시 코드에서는 OCR 데이터에서 직접적인 정보를 추출하지 않으며, 실제 구현에 필요한 로직 추가가 필요합니다.\n",
    "\n",
    "        data_item = {\n",
    "            'question': item['question'],\n",
    "            'image_id': item['image_local_name'].split('.')[0],  # 이미지 ID를 파일 이름에서 추출\n",
    "            'image_classes': None,  # 필요한 경우 채워넣어야 함\n",
    "            'extra_info': item.get('image_url'),  # 추가 정보로 이미지 URL 사용\n",
    "            'image_width': image_width,  # 이미지 처리를 통해 추출\n",
    "            'image_height': image_height,  # 이미지 처리를 통해 추출\n",
    "            'question_tokens': None,  # NLP 라이브러리를 사용해 질문 토큰화\n",
    "            'question_id': item['questionId'],\n",
    "            'set_name': item['data_split'],\n",
    "            'image_name': item['image_local_name'],\n",
    "            'image_path': f\"images/{item['image_local_name']}\",  # 이미지 파일 경로\n",
    "            'feature_path': None,  # 이미지 특성 처리 후의 경로, 필요시 설정\n",
    "            # 'ocr_tokens': ocr_data.get('tokens', []),  # OCR 데이터 구조에 따라 조정 필요\n",
    "            'ocr_tokens': ocr_tokens,  # OCR 데이터 구조에 따라 조정 필요\n",
    "            'ocr_info': ocr_data,  # 전체 OCR 데이터\n",
    "            'ocr_normalized_boxes': ocr_normalized_boxes,  # OCR 데이터에서 추출, 필요시 처리\n",
    "            'obj_normalized_boxes': None,  # 객체 인식 결과, 필요시 처리\n",
    "            'answers': item['answers'],\n",
    "            'valid_answers': item['answers']  # 유효한 답변, 처리 방식에 따라 다를 수 있음\n",
    "        }\n",
    "        imdb_data.append(data_item)\n",
    "        \n",
    "        \n",
    "\n",
    "    # print(imdb_data[0]['ocr_tokens'])\n",
    "    # print(imdb_data[0]['question'])\n",
    "    # print(imdb_data[0]['image_id'])\n",
    "\n",
    "    # print(imdb_data[0]['question_id'])\n",
    "    # print(imdb_data[0]['image_name'])\n",
    "    # for item in imdb_data[0]['ocr_info']['WORD']:\n",
    "    #     print(item)\n",
    "    # NumPy 배열로 변환\n",
    "    imdb_array = np.array(imdb_data, dtype=object)\n",
    "    np.save(file_name, imdb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./hy_info/task3/'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_npy(data_train,default_path+'/imdb/infographics_imdb_train.npy')\n",
    "image_to_npy(data_valid,default_path+'/imdb/infographics_imdb_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test .npy 만드는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(default_path+'/qas//infographicsVQA_test_v1.0.json', 'r') as file:\n",
    "    data_test = json.load(file)\n",
    "# data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for item in data_test['data']:\n",
    "    \n",
    "    image_path = default_path+f\"/images/{item['image_local_name']}\"  # 이미지 폴더 경로 수정\n",
    "    \n",
    "    # 이미지 크기 정보를 읽음\n",
    "    with Image.open(image_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "    \n",
    "    \n",
    "    # OCR 출력 파일 로드\n",
    "    with open(default_path+f\"/ocrs/{item['ocr_output_file']}\", 'r') as ocr_file:\n",
    "        ocr_data = json.load(ocr_file)\n",
    "    ocr_tokens = []\n",
    "    ocr_normalized_boxes = []\n",
    "    \n",
    "    # print(ocr_data.keys())\n",
    "    if 'WORD' in ocr_data :\n",
    "        for word_info in ocr_data['WORD']:\n",
    "        # OCR 토큰 추가\n",
    "            ocr_tokens.append(word_info['Text'])\n",
    "\n",
    "        # BoundingBox 정보를 사용하여 정규화된 박스 생성\n",
    "        # 'Left', 'Top'은 박스의 좌상단 좌표, 'Width', 'Height'는 박스의 너비와 높이입니다.\n",
    "            bounding_box = word_info['Geometry']['BoundingBox']\n",
    "            \n",
    "            normalized_box = [\n",
    "                bounding_box['Left'],\n",
    "                bounding_box['Top'],\n",
    "                bounding_box['Left'] + bounding_box['Width'],\n",
    "                bounding_box['Top'] + bounding_box['Height']\n",
    "            ]\n",
    "            ocr_normalized_boxes.append(normalized_box)\n",
    "    else :\n",
    "        print(False)\n",
    "    \n",
    "    # print(ocr_tokens)\n",
    "    # print(ocr_normalized_boxes)\n",
    "    # 이미지 사이즈, OCR 정보 등을 필요에 따라 처리\n",
    "    # 예시 코드에서는 OCR 데이터에서 직접적인 정보를 추출하지 않으며, 실제 구현에 필요한 로직 추가가 필요합니다.\n",
    "\n",
    "    data_item = {\n",
    "        'question': item['question'],\n",
    "        'image_id': item['image_local_name'].split('.')[0],  # 이미지 ID를 파일 이름에서 추출\n",
    "        'image_classes': None,  # 필요한 경우 채워넣어야 함\n",
    "        'extra_info': item.get('image_url'),  # 추가 정보로 이미지 URL 사용\n",
    "        'image_width': image_width,  # 이미지 처리를 통해 추출\n",
    "        'image_height': image_height,  # 이미지 처리를 통해 추출\n",
    "        'question_tokens': None,  # NLP 라이브러리를 사용해 질문 토큰화\n",
    "        'question_id': item['questionId'],\n",
    "        'set_name': item['data_split'],\n",
    "        'image_name': item['image_local_name'],\n",
    "        'image_path': f\"images/{item['image_local_name']}\",  # 이미지 파일 경로\n",
    "        'feature_path': None,  # 이미지 특성 처리 후의 경로, 필요시 설정\n",
    "        # 'ocr_tokens': ocr_data.get('tokens', []),  # OCR 데이터 구조에 따라 조정 필요\n",
    "        'ocr_tokens': ocr_tokens,  # OCR 데이터 구조에 따라 조정 필요\n",
    "        'ocr_info': ocr_data,  # 전체 OCR 데이터\n",
    "        'ocr_normalized_boxes': ocr_normalized_boxes,  # OCR 데이터에서 추출, 필요시 처리\n",
    "        'obj_normalized_boxes': None,  # 객체 인식 결과, 필요시 처리\n",
    "        # test 만들때는 정답 빼줘야함\n",
    "        # 'answers': item['answers'],\n",
    "        # 'valid_answers': item['answers']  # 유효한 답변, 처리 방식에 따라 다를 수 있음  \n",
    "    }\n",
    "    imdb_data.append(data_item)\n",
    "    \n",
    "    \n",
    "\n",
    "# print(imdb_data[0]['ocr_tokens'])\n",
    "# print(imdb_data[0]['question'])\n",
    "# print(imdb_data[0]['image_id'])\n",
    "\n",
    "# print(imdb_data[0]['question_id'])\n",
    "# print(imdb_data[0]['image_name'])\n",
    "# for item in imdb_data[0]['ocr_info']['WORD']:\n",
    "#     print(item)\n",
    "# NumPy 배열로 변환\n",
    "imdb_array = np.array(imdb_data, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(default_path+'/imdb/infographics_imdb_test.npy', imdb_array)\n",
    "# image_to_npy(data_train,default_path+'/imdb/infographics_imdb_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
